{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/opt/anaconda3/lib/python36.zip',\n",
       " '/opt/anaconda3/lib/python3.6',\n",
       " '/opt/anaconda3/lib/python3.6/lib-dynload',\n",
       " '/opt/anaconda3/lib/python3.6/site-packages',\n",
       " '/opt/anaconda3/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/desenfirman/.ipython',\n",
       " '/media/Data/desenfirman/development/som-clustering-knn-imputation']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "sys.path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_algorithm import self_organizing_maps as som\n",
    "from main_algorithm import knn_imputation as knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette data 0 Cluster  0;0; : 0.4315345054355205\n",
      "Silhouette data 26 Cluster  0;0; : 0.34310493256501773\n",
      "Silhouette data 1 Cluster  2;0; : 1.0\n",
      "Silhouette data 2 Cluster  3;4; : 1.0\n",
      "Silhouette data 3 Cluster  0;3; : -0.33005483552213816\n",
      "Silhouette data 10 Cluster  0;3; : -0.13670539245604302\n",
      "Silhouette data 4 Cluster  3;1; : 0.11674281566011332\n",
      "Silhouette data 17 Cluster  3;1; : 0.12397873605719303\n",
      "Silhouette data 5 Cluster  4;2; : 0.1544125134732646\n",
      "Silhouette data 22 Cluster  4;2; : 0.01420799274319592\n",
      "Silhouette data 6 Cluster  4;3; : 1.0\n",
      "Silhouette data 7 Cluster  3;3; : 0.1747814588241452\n",
      "Silhouette data 15 Cluster  3;3; : 0.1961986832212206\n",
      "Silhouette data 18 Cluster  3;3; : 0.09639770410771295\n",
      "Silhouette data 19 Cluster  3;3; : 0.15957402281138283\n",
      "Silhouette data 21 Cluster  3;3; : 0.18074971532866904\n",
      "Silhouette data 8 Cluster  0;4; : 1.0\n",
      "Silhouette data 9 Cluster  4;4; : 1.0\n",
      "Silhouette data 11 Cluster  0;1; : 0.659022054608929\n",
      "Silhouette data 25 Cluster  0;1; : 0.5918386520116135\n",
      "Silhouette data 30 Cluster  0;1; : 0.48217969580808034\n",
      "Silhouette data 33 Cluster  0;1; : 0.5352543701127284\n",
      "Silhouette data 34 Cluster  0;1; : 0.6623073564395859\n",
      "Silhouette data 35 Cluster  0;1; : 0.6972101277557959\n",
      "Silhouette data 37 Cluster  0;1; : 0.6579664698419757\n",
      "Silhouette data 12 Cluster  2;3; : -0.17670914429492102\n",
      "Silhouette data 20 Cluster  2;3; : -0.20415141003452625\n",
      "Silhouette data 13 Cluster  1;3; : -0.0139681914769521\n",
      "Silhouette data 36 Cluster  1;3; : 0.2170349255405034\n",
      "Silhouette data 14 Cluster  2;2; : 1.0\n",
      "Silhouette data 16 Cluster  3;2; : 1.0\n",
      "Silhouette data 23 Cluster  0;2; : 1.0\n",
      "Silhouette data 24 Cluster  2;4; : 1.0\n",
      "Silhouette data 27 Cluster  1;0; : 1.0\n",
      "Silhouette data 28 Cluster  2;1; : 1.0\n",
      "Silhouette data 29 Cluster  1;2; : 0.025380123206648796\n",
      "Silhouette data 31 Cluster  1;2; : 0.38489999810299297\n",
      "Silhouette data 32 Cluster  1;1; : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.4315345054355205,\n",
       " 26: 0.34310493256501773,\n",
       " 1: 1.0,\n",
       " 2: 1.0,\n",
       " 3: -0.33005483552213816,\n",
       " 10: -0.13670539245604302,\n",
       " 4: 0.11674281566011332,\n",
       " 17: 0.12397873605719303,\n",
       " 5: 0.1544125134732646,\n",
       " 22: 0.01420799274319592,\n",
       " 6: 1.0,\n",
       " 7: 0.1747814588241452,\n",
       " 15: 0.1961986832212206,\n",
       " 18: 0.09639770410771295,\n",
       " 19: 0.15957402281138283,\n",
       " 21: 0.18074971532866904,\n",
       " 8: 1.0,\n",
       " 9: 1.0,\n",
       " 11: 0.659022054608929,\n",
       " 25: 0.5918386520116135,\n",
       " 30: 0.48217969580808034,\n",
       " 33: 0.5352543701127284,\n",
       " 34: 0.6623073564395859,\n",
       " 35: 0.6972101277557959,\n",
       " 37: 0.6579664698419757,\n",
       " 12: -0.17670914429492102,\n",
       " 20: -0.20415141003452625,\n",
       " 13: -0.0139681914769521,\n",
       " 36: 0.2170349255405034,\n",
       " 14: 1.0,\n",
       " 16: 1.0,\n",
       " 23: 1.0,\n",
       " 24: 1.0,\n",
       " 27: 1.0,\n",
       " 28: 1.0,\n",
       " 29: 0.025380123206648796,\n",
       " 31: 0.38489999810299297,\n",
       " 32: 1.0,\n",
       " 'avg': 0.4748207336808343}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset to jupyter notebook\n",
    "from pandas import read_csv\n",
    "\n",
    "def extract_dataset(file):\n",
    "    dataset = read_csv(file)\n",
    "    new_columns = dataset.columns.values\n",
    "    new_columns[0] = 'First_Column'\n",
    "    dataset.columns = new_columns\n",
    "    dataset = dataset.set_index('First_Column')\n",
    "    raw_dataset = dataset\n",
    "    return raw_dataset\n",
    "\n",
    "dataset = extract_dataset(\"../dataset_used/dataset_PMKS.csv\")\n",
    "dataset\n",
    "\n",
    "dataset_used = dataset.iloc[:, :].values\n",
    "dataset_knn_ed = knn.impute_dataset(dataset_used, 0)\n",
    "dataset_norm = som.normalize_data(dataset_knn_ed)\n",
    "\n",
    "attr_size = len(dataset_used[0])\n",
    "weight = som.init_som_net(2, 2, attr_size)\n",
    "trained_weight = som.training(dataset_norm, weight, 50, 1, 0.7)\n",
    "som.silhouette(trained_weight, dataset_norm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian parameter nilai learning rate (alpha)\n",
    "\n",
    "Nilai yang akan diujikan\n",
    "- 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1\n",
    "\n",
    "Variabel kontrol\n",
    "- Nilai eta = 0.1\n",
    "- Jumlah epoch = 200\n",
    "- Jumlah neuron = 5x5\n",
    "- Nilai K = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.1, Eta: 0.1, Epoch: 200, Jumlah Neuron:(5, 5), K: 0 Try: 1\n",
      "Progress: 11.5% QE:1.02300231150528269532106475476\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bb1759cd2c8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Alpha: {0}, Eta: {1}, Epoch: {2}, Jumlah Neuron:{3}, K: {4} Try: {5}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjumlah_neuron\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_som_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjumlah_neuron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjumlah_neuron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtrained_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mqe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nQE: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/desenfirman/development/som-clustering-knn-imputation/main_algorithm/self_organizing_maps.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(dataset_input, input_weight, max_epoch, alpha_0, eta_0)\u001b[0m\n\u001b[1;32m     89\u001b[0m         print(\"Progress: {0}% QE:{1}\".format(\n\u001b[1;32m     90\u001b[0m             (float(t) / max_epoch) * 100, quantization_error(\n\u001b[0;32m---> 91\u001b[0;31m                 trained_weight, dataset_input)), end='\\r', flush=True)\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/desenfirman/development/som-clustering-knn-imputation/main_algorithm/self_organizing_maps.py\u001b[0m in \u001b[0;36mquantization_error\u001b[0;34m(trained_weight, dataset_input)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0msum_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata_input\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mdist_data_to_neur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dist_data_from_neur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mdist_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_data_to_neur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0msum_dist\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdist_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# access distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/Data/desenfirman/development/som-clustering-knn-imputation/main_algorithm/self_organizing_maps.py\u001b[0m in \u001b[0;36mget_dist_data_from_neur\u001b[0;34m(trained_weight, input_data)\u001b[0m\n\u001b[1;32m     50\u001b[0m                     attr] - trained_weight[neur_i][neur_j][attr]) ** 2\n\u001b[1;32m     51\u001b[0m             \u001b[0mrootsumsq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msumsq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mdist_data_to_neur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneur_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneur_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrootsumsq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdist_data_to_neur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "# value to be tested\n",
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "# parameter control\n",
    "eta = 0.1\n",
    "epoch = 200\n",
    "jumlah_neuron = (5,5)\n",
    "k = 0\n",
    "\n",
    "n_test = 10\n",
    "\n",
    "qes = dict()\n",
    "\n",
    "\n",
    "dataset_used = dataset.iloc[:, :].values\n",
    "dataset_knn_ed = knn.impute_dataset(dataset_used, k)\n",
    "dataset_norm = som.normalize_data(dataset_knn_ed)\n",
    "\n",
    "for alpha in alphas:\n",
    "    sum_all = 0\n",
    "    qe_n = dict()\n",
    "    for n in range(n_test):\n",
    "        attr_size = len(dataset_used[0])\n",
    "        print(\"Alpha: {0}, Eta: {1}, Epoch: {2}, Jumlah Neuron:{3}, K: {4} Try: {5}\".format(alpha, eta, epoch, jumlah_neuron, k, n+1), end='\\n')\n",
    "        weight = som.init_som_net(jumlah_neuron[0], jumlah_neuron[1], attr_size)\n",
    "        trained_weight = som.training(dataset_norm, weight, epoch, alpha, eta)\n",
    "        qe = som.quantization_error(trained_weight, dataset_norm)\n",
    "        print(\"\\nQE: {0}\".format(qe), end='\\n', flush=True)\n",
    "        qe_n[n + 1] = qe\n",
    "        sum_all += qe\n",
    "    qe_n['avg'] = sum_all / n_test\n",
    "    qes[str(alpha)] = qe_n\n",
    "    clear_output()\n",
    "\n",
    "(df.from_dict(qes)).to_csv('alpha_testing_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian parameter nilai signifikasi update bobot (eta)\n",
    "\n",
    "Nilai yang akan diujikan\n",
    "- 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1\n",
    "\n",
    "Variabel kontrol\n",
    "- Nilai alpha = 1\n",
    "- Jumlah epoch = 200\n",
    "- Jumlah neuron = 5x5\n",
    "- Nilai K = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "# value to be tested\n",
    "etas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "\n",
    "# parameter control\n",
    "alpha = 1\n",
    "epoch = 200\n",
    "jumlah_neuron = (5,5)\n",
    "k = 0\n",
    "\n",
    "n_test = 10\n",
    "\n",
    "qes = dict()\n",
    "\n",
    "\n",
    "dataset_used = dataset.iloc[:, :].values\n",
    "dataset_knn_ed = knn.impute_dataset(dataset_used, k)\n",
    "dataset_norm = som.normalize_data(dataset_knn_ed)\n",
    "\n",
    "for eta in etas:\n",
    "    sum_all = 0\n",
    "    qe_n = dict()\n",
    "    for n in range(n_test):\n",
    "        attr_size = len(dataset_used[0])\n",
    "        print(\"Alpha: {0}, Eta: {1}, Epoch: {2}, Jumlah Neuron:{3}, K: {4} Try: {5}\".format(alpha, eta, epoch, jumlah_neuron, k, n+1), end='\\n')\n",
    "        weight = som.init_som_net(jumlah_neuron[0], jumlah_neuron[1], attr_size)\n",
    "        trained_weight = som.training(dataset_norm, weight, epoch, alpha, eta)\n",
    "        qe = som.quantization_error(trained_weight, dataset_norm)\n",
    "        print(\"\\nQE: {0}\".format(qe), end='\\n', flush=True)\n",
    "        qe_n[n + 1] = qe\n",
    "        sum_all += qe\n",
    "    qe_n['avg'] = sum_all / n_test\n",
    "    qes[str(eta)] = qe_n\n",
    "\n",
    "(df.from_dict(qes)).to_csv('eta_testing_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian parameter jumlah epoch\n",
    "\n",
    "Nilai yang akan diujikan\n",
    "- 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200\n",
    "\n",
    "Variabel kontrol\n",
    "- Nilai alpha = 0.5\n",
    "- Nilai eta = 0.5\n",
    "- Jumlah neuron = 5x5\n",
    "- Nilai K = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "# value to be tested\n",
    "epochs = [13, 21, 34, 55, 89, 144, 233, 377, 610, 987]\n",
    "\n",
    "# parameter control\n",
    "alpha = 0.1\n",
    "eta = 0.7\n",
    "jumlah_neuron = (5,5)\n",
    "k = 0\n",
    "\n",
    "n_test = 10\n",
    "\n",
    "qes = dict()\n",
    "\n",
    "\n",
    "dataset_used = dataset.iloc[:, :].values\n",
    "dataset_knn_ed = knn.impute_dataset(dataset_used, k)\n",
    "dataset_norm = som.normalize_data(dataset_knn_ed)\n",
    "\n",
    "for epoch in epochs:\n",
    "    sum_all = 0\n",
    "    qe_n = dict()\n",
    "    for n in range(n_test):\n",
    "        attr_size = len(dataset_used[0])\n",
    "        print(\"Alpha: {0}, Eta: {1}, Epoch: {2}, Jumlah Neuron:{3}, K: {4} Try: {5}\".format(alpha, eta, epoch, jumlah_neuron, k, n+1), end='\\n')\n",
    "        weight = som.init_som_net(jumlah_neuron[0], jumlah_neuron[1], attr_size)\n",
    "        trained_weight = som.training(dataset_norm, weight, epoch, alpha, eta)\n",
    "        qe = som.quantization_error(trained_weight, dataset_norm)\n",
    "        print(\"\\nQE: {0}\".format(qe), end='\\n', flush=True)\n",
    "        qe_n[n + 1] = qe\n",
    "        sum_all += qe\n",
    "    qe_n['avg'] = sum_all / n_test\n",
    "    qes[str(epoch)] = qe_n\n",
    "\n",
    "(df.from_dict(qes)).to_csv('epoch_testing_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian parameter nilai jumlah neuron\n",
    "\n",
    "Nilai yang akan diujikan\n",
    "- 2x2, 3x3, 4x4, 5x5\n",
    "\n",
    "Variabel kontrol\n",
    "- Nilai alpha = 1\n",
    "- Nilai eta = 0.7\n",
    "- Jumlah epoch = 600\n",
    "- Nilai K = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(2, 2), K: 0 Try: 1\n",
      "Progress: 100.0% QE:0.888861829613355261933933050471\n",
      "QE: 2.308778899908144\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(2, 2), K: 0 Try: 2\n",
      "Progress: 100.0% QE:0.888861829613355261933933050471\n",
      "QE: 2.308778899908144\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(2, 2), K: 0 Try: 3\n",
      "Progress: 100.0% QE:0.888861829613355261933933050471\n",
      "QE: 2.308778899908144\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(2, 2), K: 0 Try: 4\n",
      "Progress: 100.0% QE:0.888861829613355261933933050471\n",
      "QE: 2.308778899908144\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(2, 2), K: 0 Try: 5\n",
      "Progress: 100.0% QE:0.888861829613355261933933050471\n",
      "QE: 2.308778899908144\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(2, 2), K: 0 Try: 6\n",
      "Progress: 100.0% QE:0.888861829613355261933933050471\n",
      "QE: 2.308778899908144\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(2, 2), K: 0 Try: 7\n",
      "Progress: 100.0% QE:0.888861829613355261933933050471\n",
      "QE: 2.308778899908144\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(2, 2), K: 0 Try: 8\n",
      "Progress: 100.0% QE:0.888861829613355261933933050471\n",
      "QE: 2.308778899908144\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(2, 2), K: 0 Try: 9\n",
      "Progress: 100.0% QE:0.888861829613355261933933050471\n",
      "QE: 2.308778899908144\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(2, 2), K: 0 Try: 10\n",
      "Progress: 100.0% QE:0.888861829613355261933933050471\n",
      "QE: 2.308778899908144\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(3, 3), K: 0 Try: 1\n",
      "Progress: 100.0% QE:0.764741214958369391221120307924\n",
      "QE: 2.1489851859623386\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(3, 3), K: 0 Try: 2\n",
      "Progress: 100.0% QE:0.753967323722750783291848613943\n",
      "QE: 2.1919723922278425\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(3, 3), K: 0 Try: 3\n",
      "Progress: 100.0% QE:0.760953330978401974655516960841\n",
      "QE: 2.2593591288511807\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(3, 3), K: 0 Try: 4\n",
      "Progress: 100.0% QE:0.760953330978401974655516960841\n",
      "QE: 2.2593591288511807\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(3, 3), K: 0 Try: 5\n",
      "Progress: 100.0% QE:0.771449262766781957932882272394\n",
      "QE: 2.344589392034325\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(3, 3), K: 0 Try: 6\n",
      "Progress: 100.0% QE:0.757034722561783150966250073421\n",
      "QE: 1.9624097776623168\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(3, 3), K: 0 Try: 7\n",
      "Progress: 100.0% QE:0.789768235202488739166617042396\n",
      "QE: 2.3150534688338897\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(3, 3), K: 0 Try: 8\n",
      "Progress: 100.0% QE:0.755637671497636964869239420846\n",
      "QE: 1.8950995674173614\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(3, 3), K: 0 Try: 9\n",
      "Progress: 100.0% QE:0.757880867288391888525736142412\n",
      "QE: 2.2584134372688593\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(3, 3), K: 0 Try: 10\n",
      "Progress: 100.0% QE:0.764741214958369391221120307924\n",
      "QE: 2.1489851859623386\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(4, 4), K: 0 Try: 1\n",
      "Progress: 100.0% QE:0.542780676355319285365890841745\n",
      "QE: 1.4448430607101106\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(4, 4), K: 0 Try: 2\n",
      "Progress: 100.0% QE:0.573071012492910456428260797851\n",
      "QE: 1.460106195528445\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(4, 4), K: 0 Try: 3\n",
      "Progress: 100.0% QE:0.580259933418255448453856724375\n",
      "QE: 1.60204971194055\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(4, 4), K: 0 Try: 4\n",
      "Progress: 100.0% QE:0.562556910565707277295371302151\n",
      "QE: 1.573138785614073\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(4, 4), K: 0 Try: 5\n",
      "Progress: 100.0% QE:0.583192927671325270720889252677\n",
      "QE: 1.4400363614603755\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(4, 4), K: 0 Try: 6\n",
      "Progress: 100.0% QE:0.538267862082026693016905125192\n",
      "QE: 1.4230570661338222\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(4, 4), K: 0 Try: 7\n",
      "Progress: 100.0% QE:0.605733613756296402542360988451\n",
      "QE: 1.7284890653755556\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(4, 4), K: 0 Try: 8\n",
      "Progress: 100.0% QE:0.587339540178328530506946942869\n",
      "QE: 1.6630903892508444\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(4, 4), K: 0 Try: 9\n",
      "Progress: 100.0% QE:0.583150603723649421908296298474\n",
      "QE: 1.7152603581192174\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(4, 4), K: 0 Try: 10\n",
      "Progress: 100.0% QE:0.581625727778948730837536113599\n",
      "QE: 1.7383137835016051\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(5, 5), K: 0 Try: 1\n",
      "Progress: 100.0% QE:0.435892258502022763039951944658\n",
      "QE: 1.3378611326826062\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(5, 5), K: 0 Try: 2\n",
      "Progress: 100.0% QE:0.452552286798226879003801192134\n",
      "QE: 1.5740552517624034\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(5, 5), K: 0 Try: 3\n",
      "Progress: 100.0% QE:0.498442030489139761490681504251\n",
      "QE: 1.4143181424794404\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(5, 5), K: 0 Try: 4\n",
      "Progress: 100.0% QE:0.445316004275691461981214463159\n",
      "QE: 1.4640870339840737\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(5, 5), K: 0 Try: 5\n",
      "Progress: 100.0% QE:0.414147249128959667226460402145\n",
      "QE: 1.4665953643837832\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(5, 5), K: 0 Try: 6\n",
      "Progress: 100.0% QE:0.441960856979606143702214061739\n",
      "QE: 1.8045221194543566\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(5, 5), K: 0 Try: 7\n",
      "Progress: 100.0% QE:0.464474994636552806545169952467\n",
      "QE: 1.5903472508639163\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(5, 5), K: 0 Try: 8\n",
      "Progress: 100.0% QE:0.409527747827889707286821395576\n",
      "QE: 1.4796567362829194\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(5, 5), K: 0 Try: 9\n",
      "Progress: 100.0% QE:0.434725354642179431269538361236\n",
      "QE: 1.665602626345544\n",
      "Alpha: 1, Eta: 0.7, Epoch: 600, Jumlah Neuron:(5, 5), K: 0 Try: 10\n",
      "Progress: 100.0% QE:0.447450815145084174510514899634\n",
      "QE: 1.4849729027588308\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "from pandas import DataFrame as df\n",
    "import json\n",
    "\n",
    "# value to be tested\n",
    "eta = 0.7\n",
    "\n",
    "# parameter control\n",
    "alpha = 1\n",
    "epoch = 600\n",
    "jumlah_neurons = [(2,2), (3,3), (4,4), (5,5)]\n",
    "k = 0\n",
    "\n",
    "n_test = 10\n",
    "\n",
    "qes = dict()\n",
    "\n",
    "\n",
    "dataset_used = dataset.iloc[:, :].values\n",
    "dataset_knn_ed = knn.impute_dataset(dataset_used, k)\n",
    "dataset_norm = som.normalize_data(dataset_knn_ed)\n",
    "\n",
    "def cluster_build(dataset_indexes, dataset_input, trained_weight):\n",
    "    cluster_result = dict()\n",
    "    cls_list = list()\n",
    "    for idx, x_data in enumerate(dataset_input):\n",
    "        indexes = dataset_indexes[idx]\n",
    "        c = som.penentuan_cluster(trained_weight, x_data)\n",
    "        cls_id = str(c[0]) + ';' + str(c[1]) + ';'\n",
    "        if cls_id not in cls_list:\n",
    "            cls_list.append(cls_id)\n",
    "            cluster_result[cls_id] = list()\n",
    "        cluster_result[cls_id].append(indexes)\n",
    "    return cluster_result\n",
    "    \n",
    "\n",
    "for jumlah_neuron in jumlah_neurons:\n",
    "    sum_all = 0\n",
    "    qe_n = dict()\n",
    "    min_qe = 999999\n",
    "    for n in range(n_test):\n",
    "        attr_size = len(dataset_used[0])\n",
    "        print(\"Alpha: {0}, Eta: {1}, Epoch: {2}, Jumlah Neuron:{3}, K: {4} Try: {5}\".format(alpha, eta, epoch, jumlah_neuron, k, n+1), end='\\n')\n",
    "        weight = som.init_som_net(jumlah_neuron[0], jumlah_neuron[1], attr_size)\n",
    "        trained_weight = som.training(dataset_norm, weight, epoch, alpha, eta)\n",
    "        qe = som.davies_bouldin_index(trained_weight, dataset_norm)\n",
    "        print(\"\\nQE: {0}\".format(qe), end='\\n', flush=True)\n",
    "        qe_n[n + 1] = qe\n",
    "        sum_all += qe\n",
    "        \n",
    "        if qe < min_qe:\n",
    "            min_qe = qe\n",
    "            cls_result = cluster_build(dataset.index, dataset_norm, trained_weight)\n",
    "            cls_result['score'] = min_qe\n",
    "            with open('neuron_test_result/' + str(jumlah_neuron) + '.json', 'w') as file:\n",
    "                file.write(json.dumps(cls_result))\n",
    "    qe_n['avg'] = sum_all / n_test\n",
    "    qes[str(jumlah_neuron)] = qe_n\n",
    "\n",
    "(df.from_dict(qes)).to_csv('jumlah_neuron_testing_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengujian parameter nilai K\n",
    "\n",
    "Nilai yang akan diujikan\n",
    "- 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1\n",
    "\n",
    "Variabel kontrol\n",
    "- Nilai eta = 0.5\n",
    "- Jumlah epoch = 200\n",
    "- Jumlah neuron = 5x5\n",
    "- Nilai K = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "# value to be tested\n",
    "epochs = [13, 21, 34, 55, 89, 144, 233, 377, 610, 987]\n",
    "\n",
    "# parameter control\n",
    "alpha = 0.1\n",
    "eta = 0.7\n",
    "jumlah_neuron = (5,5)\n",
    "k = 0\n",
    "\n",
    "n_test = 10\n",
    "\n",
    "qes = dict()\n",
    "\n",
    "\n",
    "dataset_used = dataset.iloc[:, :].values\n",
    "dataset_knn_ed = knn.impute_dataset(dataset_used, k)\n",
    "dataset_norm = som.normalize_data(dataset_knn_ed)\n",
    "\n",
    "for epoch in epochs:\n",
    "    sum_all = 0\n",
    "    qe_n = dict()\n",
    "    for n in range(n_test):\n",
    "        attr_size = len(dataset_used[0])\n",
    "        print(\"Alpha: {0}, Eta: {1}, Epoch: {2}, Jumlah Neuron:{3}, K: {4} Try: {5}\".format(alpha, eta, epoch, jumlah_neuron, k, n+1), end='\\n')\n",
    "        weight = som.init_som_net(jumlah_neuron[0], jumlah_neuron[1], attr_size)\n",
    "        trained_weight = som.training(dataset_norm, weight, epoch, alpha, eta)\n",
    "        qe = som.quantization_error(trained_weight, dataset_norm)\n",
    "        print(\"\\nQE: {0}\".format(qe), end='\\n', flush=True)\n",
    "        qe_n[n + 1] = qe\n",
    "        sum_all += qe\n",
    "            \n",
    "    qe_n['avg'] = sum_all / n_test\n",
    "    qes[str(epoch)] = qe_n\n",
    "\n",
    "(df.from_dict(qes)).to_csv('epoch_testing_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dict()\n",
    "len(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
